{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RihabTsi/Project-Data-Science/blob/main/IMBD_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBbnkOCV0nno",
        "outputId": "78a7923b-e81c-42c2-97fe-82cd24e46bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2723u39054m",
        "outputId": "cc9bc2b9-2161-4058-f69e-7e8b5e2b156a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "import nltk\n",
        "\n",
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EL5ZZyH1VHP"
      },
      "source": [
        "# Read file with labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0HkH1s711Y-7",
        "outputId": "b26f7233-488d-4778-ce94-d68ed9ff0a26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Critiques  Label\n",
              "0  I went and saw this movie last night after bei...      1\n",
              "1  Actor turned director Bill Paxton follows up h...      1\n",
              "2  As a recreational golfer with some knowledge o...      1\n",
              "3  I saw this film in a sneak preview, and it is ...      1\n",
              "4  Bill Paxton has taken the true story of the 19...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a61425c-4cb1-49b7-b09c-11e8e8344a36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Critiques</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a61425c-4cb1-49b7-b09c-11e8e8344a36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a61425c-4cb1-49b7-b09c-11e8e8344a36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a61425c-4cb1-49b7-b09c-11e8e8344a36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ESG_BIG_DATA/Machine Learning/TP1 Critique IMBS/IMBD.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sUpfVwm8iAeQ"
      },
      "outputs": [],
      "source": [
        "df.rename(columns = {'Critiques':'text'}, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "U66mhTcghUlS",
        "outputId": "4e5aa2bb-d596-4a8d-b8b3-58c3fd3ced97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  Label\n",
              "0      I went and saw this movie last night after bei...      1\n",
              "1      Actor turned director Bill Paxton follows up h...      1\n",
              "2      As a recreational golfer with some knowledge o...      1\n",
              "3      I saw this film in a sneak preview, and it is ...      1\n",
              "4      Bill Paxton has taken the true story of the 19...      1\n",
              "...                                                  ...    ...\n",
              "24995  I occasionally let my kids watch this garbage ...      0\n",
              "24996  When all we have anymore is pretty much realit...      0\n",
              "24997  The basic genre is a thriller intercut with an...      0\n",
              "24998  Four things intrigued me as to this film - fir...      0\n",
              "24999  David Bryce's comments nearby are exceptionall...      0\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92b4f526-99a9-42a1-8342-823b9a14135d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>I occasionally let my kids watch this garbage ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>When all we have anymore is pretty much realit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>The basic genre is a thriller intercut with an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>Four things intrigued me as to this film - fir...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92b4f526-99a9-42a1-8342-823b9a14135d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92b4f526-99a9-42a1-8342-823b9a14135d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92b4f526-99a9-42a1-8342-823b9a14135d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oKaWyXbWiKpr"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "GRwbh5HdgCNy",
        "outputId": "99f17229-0c64-41e4-f1c1-f8edff99c4b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A delightful story about two evacuees, has been turned into a nice little film, by the BBC. Most children who like a good story will enjoy this. The characters are played really well by a very good cast. Not sure whether our American friends will appreciate it, but they do get a mention, as Aunty Lou runs off with a gorgeous American soldier.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_ds=df[:17500]\n",
        "train_ds.text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eUbw4BGYgMa-",
        "outputId": "45d6987d-35db-477e-fd3d-064cd89e06f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  Label\n",
              "0  This movie isn't worth going to the theaters t...      0\n",
              "1  This movie was not very good in my opinion. Wh...      0\n",
              "2  \"Lights of New York\" originally started out as...      1\n",
              "3  Admirable but weak James Bond film mainly beca...      0\n",
              "4  Quentin in my opinion has written and directed...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e048469c-2cfa-402e-9842-a66eed96b58e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie isn't worth going to the theaters t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This movie was not very good in my opinion. Wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Lights of New York\" originally started out as...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Admirable but weak James Bond film mainly beca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quentin in my opinion has written and directed...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e048469c-2cfa-402e-9842-a66eed96b58e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e048469c-2cfa-402e-9842-a66eed96b58e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e048469c-2cfa-402e-9842-a66eed96b58e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_ds = df[17500:]\n",
        "test_ds = test_ds.reset_index(drop=True)\n",
        "test_ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHL4uJNaiWqn"
      },
      "source": [
        "# Embedding **layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn1j35G5h0-s",
        "outputId": "05ab7b21-c22d-432a-eb75-497c83e38bc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02673417, -0.00708727,  0.01658465, -0.04912126,  0.01368606],\n",
              "       [ 0.01869703,  0.04622107, -0.00688421,  0.02454608,  0.01546058],\n",
              "       [ 0.03208982, -0.03843373,  0.03708104,  0.02728727,  0.00488452]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Embed a 1,000 words/tokens vocabulary into 5 dimensions.\n",
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n",
        "# We create a random list of three integers and use it as input for the embedding\n",
        "# layer and take a look at the output.\n",
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()\n",
        "\n",
        "# The result is a collection of three 5-dimensional vectors. Each element in the \n",
        "# original list has been replaced by a vector of 5 floating points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8HscM3NiFQu",
        "outputId": "24a3af62-fee1-434e-b67b-d948a8d36595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1000, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# The shape of the trainable_variables attribute confirms what we just explained.\n",
        "embedding_layer.trainable_variables[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfYtckZ79PEb"
      },
      "source": [
        "# **Pre-Processing** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfoiVzZzix1Z",
        "outputId": "19342e95-4de1-4045-97ce-878fc834875b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-03 20:36:02.332386: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.2 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# We start by downloading spacy for the english language\n",
        "!python -m spacy download en_core_web_sm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KZ0waQ4si0Xt"
      },
      "outputs": [],
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9cuj0EIMi2K1"
      },
      "outputs": [],
      "source": [
        "# Import Stop words \n",
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9dz_rgbfqxLC"
      },
      "outputs": [],
      "source": [
        "#Cleaning TEXT\n",
        "def sentence_rge(data):\n",
        "    data=re.sub('<[^>]*>','',data) # Html taglerini kaldırma\n",
        "    emoji=re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',data) #Emojileri bulma\n",
        "    data=re.sub('[\\W]+',' ',data.lower()) +\\\n",
        "                ' '.join(emoji).replace('-','')\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egiz0P-7Fg1Z",
        "outputId": "aa43de4e-1658-41c2-a5e7-910ce3ec30c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text before cleaning::  A delightful story about two evacuees, has been turned into a nice little film, by the BBC. Most children who like a good story will enjoy this. The characters are played really well by a very good cast. Not sure whether our American friends will appreciate it, but they do get a mention, as Aunty Lou runs off with a gorgeous American soldier.\n",
            "Text after cleaning::  a delightful story about two evacuees has been turned into a nice little film by the bbc most children who like a good story will enjoy this the characters are played really well by a very good cast not sure whether our american friends will appreciate it but they do get a mention as aunty lou runs off with a gorgeous american soldier \n"
          ]
        }
      ],
      "source": [
        "print(\"Text before cleaning:: \",train_ds.text[0])\n",
        "print(\"Text after cleaning:: \", train_ds.text.apply(sentence_rge)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpdVlgVibPYg",
        "outputId": "a20a048f-bd48-4566-9564-146403838c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#Clean the columns text\n",
        "train_ds['text_clean']=train_ds[\"text\"].apply(sentence_rge)\n",
        "# Remove all non alphanumeric characters except whitespaces\n",
        "train_ds[\"text_clean\"] = train_ds['text_clean'].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
        "# remove double spaces and spaces at the beginning and end of strings\n",
        "train_ds[\"text_clean\"] = train_ds['text_clean'].apply(lambda x: x.replace(\" +\",\" \").lower().strip())\n",
        "# remove stop words and replace everyword with their lemma\n",
        "train_ds[\"text_clean\"] = train_ds[\"text_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) & (token.text not in STOP_WORDS)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "IE1o8wDQjA3-",
        "outputId": "4729b62e-7c12-4f4b-c7ca-6c9ff4261c54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  Label  \\\n",
              "0      A delightful story about two evacuees, has bee...      1   \n",
              "1      Having already seen the original \"Jack Frost\",...      0   \n",
              "2      I have nothing but praise for this movie and c...      1   \n",
              "3      Changi has a delightfully fresh script, acted ...      1   \n",
              "4      I say Ben Johnson and my fellow Canadians say,...      0   \n",
              "...                                                  ...    ...   \n",
              "17495  Usual awful movie... I'll not bother you about...      0   \n",
              "17496  I've just revisited this fondly remembered bit...      1   \n",
              "17497  I want very much to believe that the above quo...      0   \n",
              "17498  Everyone's already commented on the obvious fa...      0   \n",
              "17499  Admittedly, I tuned into this in the hopes of ...      0   \n",
              "\n",
              "                                              text_clean  \n",
              "0      delightful story evacuee turn nice little film...  \n",
              "1      having original jack frost think jack frost 2 ...  \n",
              "2      praise movie cast especially ann margaret impo...  \n",
              "3      changi delightfully fresh script act superbly ...  \n",
              "4      ben johnson fellow canadian ben johnson goddam...  \n",
              "...                                                  ...  \n",
              "17495  usual awful movie ll bother synopsis core arma...  \n",
              "17496  ve revisit fondly remember bit cinematic madne...  \n",
              "17497  want believe quote specifically english subtit...  \n",
              "17498  s comment obvious fact comment obviously peopl...  \n",
              "17499  admittedly tune hope beefcake shot james broli...  \n",
              "\n",
              "[17500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9c5dbd1-700c-49ef-913f-cf9b333f01d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A delightful story about two evacuees, has bee...</td>\n",
              "      <td>1</td>\n",
              "      <td>delightful story evacuee turn nice little film...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Having already seen the original \"Jack Frost\",...</td>\n",
              "      <td>0</td>\n",
              "      <td>having original jack frost think jack frost 2 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have nothing but praise for this movie and c...</td>\n",
              "      <td>1</td>\n",
              "      <td>praise movie cast especially ann margaret impo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Changi has a delightfully fresh script, acted ...</td>\n",
              "      <td>1</td>\n",
              "      <td>changi delightfully fresh script act superbly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I say Ben Johnson and my fellow Canadians say,...</td>\n",
              "      <td>0</td>\n",
              "      <td>ben johnson fellow canadian ben johnson goddam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>Usual awful movie... I'll not bother you about...</td>\n",
              "      <td>0</td>\n",
              "      <td>usual awful movie ll bother synopsis core arma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17496</th>\n",
              "      <td>I've just revisited this fondly remembered bit...</td>\n",
              "      <td>1</td>\n",
              "      <td>ve revisit fondly remember bit cinematic madne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17497</th>\n",
              "      <td>I want very much to believe that the above quo...</td>\n",
              "      <td>0</td>\n",
              "      <td>want believe quote specifically english subtit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17498</th>\n",
              "      <td>Everyone's already commented on the obvious fa...</td>\n",
              "      <td>0</td>\n",
              "      <td>s comment obvious fact comment obviously peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17499</th>\n",
              "      <td>Admittedly, I tuned into this in the hopes of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>admittedly tune hope beefcake shot james broli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9c5dbd1-700c-49ef-913f-cf9b333f01d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9c5dbd1-700c-49ef-913f-cf9b333f01d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9c5dbd1-700c-49ef-913f-cf9b333f01d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QiT3x1EUrcjz"
      },
      "outputs": [],
      "source": [
        "#Train_TEST\n",
        "test_ds[\"text_clean\"] = test_ds[\"text\"].apply(sentence_rge)\n",
        "test_ds[\"text_clean\"] = test_ds[\"text_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) & (token.text not in STOP_WORDS)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6zeqVYPwshmf",
        "outputId": "8ebb71ad-d08e-4a0d-dfde-7bdfc575278d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  Label  \\\n",
              "0     This movie isn't worth going to the theaters t...      0   \n",
              "1     This movie was not very good in my opinion. Wh...      0   \n",
              "2     \"Lights of New York\" originally started out as...      1   \n",
              "3     Admirable but weak James Bond film mainly beca...      0   \n",
              "4     Quentin in my opinion has written and directed...      0   \n",
              "...                                                 ...    ...   \n",
              "7495  My wife and I saw every episode in this series...      0   \n",
              "7496  Target is the story of a special agent who, af...      0   \n",
              "7497  One of the most underrated comedies. Dan Akroy...      1   \n",
              "7498  This is the sort of unknown and forgotten film...      1   \n",
              "7499  If you're a North American 'TOURIST' looking f...      0   \n",
              "\n",
              "                                             text_clean  \n",
              "0     movie isn t worth theater watch didn t like ef...  \n",
              "1     movie good opinion complete waste hour half lu...  \n",
              "2       light new york originally start experimental...  \n",
              "3     admirable weak james bond film mainly hero bon...  \n",
              "4     quentin opinion write direct good movie multip...  \n",
              "...                                                 ...  \n",
              "7495  wife episode series love series cut short fina...  \n",
              "7496  target story special agent carry order assassi...  \n",
              "7497  underrated comedy dan akroyd hilarious role ch...  \n",
              "7498  sort unknown forget film dream discover watch ...  \n",
              "7499  north american tourist look trap trading space...  \n",
              "\n",
              "[7500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98256848-64b8-4b8c-be3f-67fa215aa912\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie isn't worth going to the theaters t...</td>\n",
              "      <td>0</td>\n",
              "      <td>movie isn t worth theater watch didn t like ef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This movie was not very good in my opinion. Wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>movie good opinion complete waste hour half lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Lights of New York\" originally started out as...</td>\n",
              "      <td>1</td>\n",
              "      <td>light new york originally start experimental...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Admirable but weak James Bond film mainly beca...</td>\n",
              "      <td>0</td>\n",
              "      <td>admirable weak james bond film mainly hero bon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quentin in my opinion has written and directed...</td>\n",
              "      <td>0</td>\n",
              "      <td>quentin opinion write direct good movie multip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7495</th>\n",
              "      <td>My wife and I saw every episode in this series...</td>\n",
              "      <td>0</td>\n",
              "      <td>wife episode series love series cut short fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7496</th>\n",
              "      <td>Target is the story of a special agent who, af...</td>\n",
              "      <td>0</td>\n",
              "      <td>target story special agent carry order assassi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7497</th>\n",
              "      <td>One of the most underrated comedies. Dan Akroy...</td>\n",
              "      <td>1</td>\n",
              "      <td>underrated comedy dan akroyd hilarious role ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>This is the sort of unknown and forgotten film...</td>\n",
              "      <td>1</td>\n",
              "      <td>sort unknown forget film dream discover watch ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7499</th>\n",
              "      <td>If you're a North American 'TOURIST' looking f...</td>\n",
              "      <td>0</td>\n",
              "      <td>north american tourist look trap trading space...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7500 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98256848-64b8-4b8c-be3f-67fa215aa912')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98256848-64b8-4b8c-be3f-67fa215aa912 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98256848-64b8-4b8c-be3f-67fa215aa912');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "test_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb8JBtYtRVq_"
      },
      "source": [
        "# **Tokenizer Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1imlaoPuL_I",
        "outputId": "14d46157-8f09-4691-9b10-be6e7c8eef11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000) # instanciate the tokenizer\n",
        "# num_words indicates the number of words to keep in the tokenization\n",
        "# keeps only the most common words\n",
        "\n",
        "tokenizer.fit_on_texts(train_ds.text_clean) # fit the tokenizer on the texts\n",
        "# in this step the tokenizer will list all unique tokens in the text\n",
        "# and associate them with a specific integer.\n",
        "\n",
        "# This step will effectively transform the texts into sequences of indices\n",
        "train_ds[\"text_encoded\"] = tokenizer.texts_to_sequences(train_ds.text_clean)\n",
        "\n",
        "# Sometimes the preprocessing removes all the words in a string (because they contain\n",
        "# only stopwords for example) so we calculate the length in order to filter out\n",
        "# those records\n",
        "train_ds[\"len_text\"] = train_ds[\"text_encoded\"].apply(lambda x: len(x))\n",
        "train_ds = train_ds[train_ds[\"len_text\"]!=0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yYFggBFQvHw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7d9fcde9-88b8-4c5f-8262-e3e5895694da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  Label  \\\n",
              "0      A delightful story about two evacuees, has bee...      1   \n",
              "1      Having already seen the original \"Jack Frost\",...      0   \n",
              "2      I have nothing but praise for this movie and c...      1   \n",
              "3      Changi has a delightfully fresh script, acted ...      1   \n",
              "4      I say Ben Johnson and my fellow Canadians say,...      0   \n",
              "...                                                  ...    ...   \n",
              "17495  Usual awful movie... I'll not bother you about...      0   \n",
              "17496  I've just revisited this fondly remembered bit...      1   \n",
              "17497  I want very much to believe that the above quo...      0   \n",
              "17498  Everyone's already commented on the obvious fa...      0   \n",
              "17499  Admittedly, I tuned into this in the hopes of ...      0   \n",
              "\n",
              "                                              text_clean  \\\n",
              "0      delightful story evacuee turn nice little film...   \n",
              "1      having original jack frost think jack frost 2 ...   \n",
              "2      praise movie cast especially ann margaret impo...   \n",
              "3      changi delightfully fresh script act superbly ...   \n",
              "4      ben johnson fellow canadian ben johnson goddam...   \n",
              "...                                                  ...   \n",
              "17495  usual awful movie ll bother synopsis core arma...   \n",
              "17496  ve revisit fondly remember bit cinematic madne...   \n",
              "17497  want believe quote specifically english subtit...   \n",
              "17498  s comment obvious fact comment obviously peopl...   \n",
              "17499  admittedly tune hope beefcake shot james broli...   \n",
              "\n",
              "                                            text_encoded  len_text  \n",
              "0      [1955, 11, 70, 195, 34, 3, 1550, 110, 5, 6, 11...        26  \n",
              "1      [530, 100, 449, 2305, 12, 449, 2305, 99, 1551,...        80  \n",
              "2      [1495, 2, 58, 123, 2093, 4068, 2613, 1495, 796...       105  \n",
              "3      [5362, 4687, 1123, 88, 36, 3026, 59, 41, 28, 2...        87  \n",
              "4      [1151, 1956, 1405, 1999, 1151, 1956, 2, 57, 39...        96  \n",
              "...                                                  ...       ...  \n",
              "17495  [499, 235, 2, 102, 626, 3236, 1338, 4957, 325,...        65  \n",
              "17496  [38, 4971, 8631, 183, 84, 1019, 2380, 151, 62,...       112  \n",
              "17497  [31, 96, 1536, 2952, 423, 1319, 3262, 49, 81, ...       213  \n",
              "17498  [1, 261, 439, 69, 261, 357, 17, 3351, 3, 79, 1...       153  \n",
              "17499  [3259, 1311, 159, 215, 433, 339, 151, 222, 2, ...       157  \n",
              "\n",
              "[17500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cb921d5-c69e-43ce-b013-fe22df5c45a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_encoded</th>\n",
              "      <th>len_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A delightful story about two evacuees, has bee...</td>\n",
              "      <td>1</td>\n",
              "      <td>delightful story evacuee turn nice little film...</td>\n",
              "      <td>[1955, 11, 70, 195, 34, 3, 1550, 110, 5, 6, 11...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Having already seen the original \"Jack Frost\",...</td>\n",
              "      <td>0</td>\n",
              "      <td>having original jack frost think jack frost 2 ...</td>\n",
              "      <td>[530, 100, 449, 2305, 12, 449, 2305, 99, 1551,...</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have nothing but praise for this movie and c...</td>\n",
              "      <td>1</td>\n",
              "      <td>praise movie cast especially ann margaret impo...</td>\n",
              "      <td>[1495, 2, 58, 123, 2093, 4068, 2613, 1495, 796...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Changi has a delightfully fresh script, acted ...</td>\n",
              "      <td>1</td>\n",
              "      <td>changi delightfully fresh script act superbly ...</td>\n",
              "      <td>[5362, 4687, 1123, 88, 36, 3026, 59, 41, 28, 2...</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I say Ben Johnson and my fellow Canadians say,...</td>\n",
              "      <td>0</td>\n",
              "      <td>ben johnson fellow canadian ben johnson goddam...</td>\n",
              "      <td>[1151, 1956, 1405, 1999, 1151, 1956, 2, 57, 39...</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>Usual awful movie... I'll not bother you about...</td>\n",
              "      <td>0</td>\n",
              "      <td>usual awful movie ll bother synopsis core arma...</td>\n",
              "      <td>[499, 235, 2, 102, 626, 3236, 1338, 4957, 325,...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17496</th>\n",
              "      <td>I've just revisited this fondly remembered bit...</td>\n",
              "      <td>1</td>\n",
              "      <td>ve revisit fondly remember bit cinematic madne...</td>\n",
              "      <td>[38, 4971, 8631, 183, 84, 1019, 2380, 151, 62,...</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17497</th>\n",
              "      <td>I want very much to believe that the above quo...</td>\n",
              "      <td>0</td>\n",
              "      <td>want believe quote specifically english subtit...</td>\n",
              "      <td>[31, 96, 1536, 2952, 423, 1319, 3262, 49, 81, ...</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17498</th>\n",
              "      <td>Everyone's already commented on the obvious fa...</td>\n",
              "      <td>0</td>\n",
              "      <td>s comment obvious fact comment obviously peopl...</td>\n",
              "      <td>[1, 261, 439, 69, 261, 357, 17, 3351, 3, 79, 1...</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17499</th>\n",
              "      <td>Admittedly, I tuned into this in the hopes of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>admittedly tune hope beefcake shot james broli...</td>\n",
              "      <td>[3259, 1311, 159, 215, 433, 339, 151, 222, 2, ...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17500 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cb921d5-c69e-43ce-b013-fe22df5c45a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cb921d5-c69e-43ce-b013-fe22df5c45a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cb921d5-c69e-43ce-b013-fe22df5c45a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FqsP5Ec-8ws5"
      },
      "outputs": [],
      "source": [
        "# We do the same on the test set, except we do not fit the tokenizer this time\n",
        "test_ds[\"text_encoded\"] = tokenizer.texts_to_sequences(test_ds.text_clean)\n",
        "test_ds[\"len_text\"] = test_ds[\"text_encoded\"].apply(lambda x: len(x))\n",
        "test_ds = test_ds[test_ds[\"len_text\"]!=0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FJOhK2rCb1Sv",
        "outputId": "e10bb07e-08e9-466f-c9c9-cce4b3d2ce68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  Label  \\\n",
              "0     This movie isn't worth going to the theaters t...      0   \n",
              "1     This movie was not very good in my opinion. Wh...      0   \n",
              "2     \"Lights of New York\" originally started out as...      1   \n",
              "3     Admirable but weak James Bond film mainly beca...      0   \n",
              "4     Quentin in my opinion has written and directed...      0   \n",
              "...                                                 ...    ...   \n",
              "7495  My wife and I saw every episode in this series...      0   \n",
              "7496  Target is the story of a special agent who, af...      0   \n",
              "7497  One of the most underrated comedies. Dan Akroy...      1   \n",
              "7498  This is the sort of unknown and forgotten film...      1   \n",
              "7499  If you're a North American 'TOURIST' looking f...      0   \n",
              "\n",
              "                                             text_clean  \\\n",
              "0     movie isn t worth theater watch didn t like ef...   \n",
              "1     movie good opinion complete waste hour half lu...   \n",
              "2       light new york originally start experimental...   \n",
              "3     admirable weak james bond film mainly hero bon...   \n",
              "4     quentin opinion write direct good movie multip...   \n",
              "...                                                 ...   \n",
              "7495  wife episode series love series cut short fina...   \n",
              "7496  target story special agent carry order assassi...   \n",
              "7497  underrated comedy dan akroyd hilarious role ch...   \n",
              "7498  sort unknown forget film dream discover watch ...   \n",
              "7499  north american tourist look trap trading space...   \n",
              "\n",
              "                                           text_encoded  len_text  \n",
              "0     [2, 87, 4, 134, 434, 9, 44, 4, 5, 97, 2, 85, 1...        40  \n",
              "1     [2, 6, 418, 363, 153, 161, 147, 3109, 44, 4, 3...       122  \n",
              "2     [320, 60, 736, 1698, 56, 3848, 2776, 135, 680,...       192  \n",
              "3     [5061, 561, 433, 862, 3, 1154, 294, 862, 560, ...        94  \n",
              "4     [4879, 418, 81, 196, 6, 2, 2139, 744, 129, 247...        65  \n",
              "...                                                 ...       ...  \n",
              "7495  [176, 124, 82, 19, 82, 277, 135, 285, 124, 435...        25  \n",
              "7496  [1389, 11, 149, 875, 550, 352, 6411, 3459, 173...       177  \n",
              "7497  [2080, 65, 1917, 376, 52, 1140, 46, 622, 6, 32...        22  \n",
              "7498  [238, 1347, 312, 3, 488, 549, 9, 41, 206, 721,...        88  \n",
              "7499  [1621, 137, 2275, 16, 1113, 470, 1010, 20, 111...        24  \n",
              "\n",
              "[7500 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a7342f3-df18-41f3-ae0a-16c72c6808e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Label</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_encoded</th>\n",
              "      <th>len_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This movie isn't worth going to the theaters t...</td>\n",
              "      <td>0</td>\n",
              "      <td>movie isn t worth theater watch didn t like ef...</td>\n",
              "      <td>[2, 87, 4, 134, 434, 9, 44, 4, 5, 97, 2, 85, 1...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This movie was not very good in my opinion. Wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>movie good opinion complete waste hour half lu...</td>\n",
              "      <td>[2, 6, 418, 363, 153, 161, 147, 3109, 44, 4, 3...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Lights of New York\" originally started out as...</td>\n",
              "      <td>1</td>\n",
              "      <td>light new york originally start experimental...</td>\n",
              "      <td>[320, 60, 736, 1698, 56, 3848, 2776, 135, 680,...</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Admirable but weak James Bond film mainly beca...</td>\n",
              "      <td>0</td>\n",
              "      <td>admirable weak james bond film mainly hero bon...</td>\n",
              "      <td>[5061, 561, 433, 862, 3, 1154, 294, 862, 560, ...</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quentin in my opinion has written and directed...</td>\n",
              "      <td>0</td>\n",
              "      <td>quentin opinion write direct good movie multip...</td>\n",
              "      <td>[4879, 418, 81, 196, 6, 2, 2139, 744, 129, 247...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7495</th>\n",
              "      <td>My wife and I saw every episode in this series...</td>\n",
              "      <td>0</td>\n",
              "      <td>wife episode series love series cut short fina...</td>\n",
              "      <td>[176, 124, 82, 19, 82, 277, 135, 285, 124, 435...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7496</th>\n",
              "      <td>Target is the story of a special agent who, af...</td>\n",
              "      <td>0</td>\n",
              "      <td>target story special agent carry order assassi...</td>\n",
              "      <td>[1389, 11, 149, 875, 550, 352, 6411, 3459, 173...</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7497</th>\n",
              "      <td>One of the most underrated comedies. Dan Akroy...</td>\n",
              "      <td>1</td>\n",
              "      <td>underrated comedy dan akroyd hilarious role ch...</td>\n",
              "      <td>[2080, 65, 1917, 376, 52, 1140, 46, 622, 6, 32...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>This is the sort of unknown and forgotten film...</td>\n",
              "      <td>1</td>\n",
              "      <td>sort unknown forget film dream discover watch ...</td>\n",
              "      <td>[238, 1347, 312, 3, 488, 549, 9, 41, 206, 721,...</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7499</th>\n",
              "      <td>If you're a North American 'TOURIST' looking f...</td>\n",
              "      <td>0</td>\n",
              "      <td>north american tourist look trap trading space...</td>\n",
              "      <td>[1621, 137, 2275, 16, 1113, 470, 1010, 20, 111...</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7500 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a7342f3-df18-41f3-ae0a-16c72c6808e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a7342f3-df18-41f3-ae0a-16c72c6808e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a7342f3-df18-41f3-ae0a-16c72c6808e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sdMYxE0iQ4tQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ba7b7a-5d4c-4102-bff0-742a3ffdc313"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 's',\n",
              " 2: 'movie',\n",
              " 3: 'film',\n",
              " 4: 't',\n",
              " 5: 'like',\n",
              " 6: 'good',\n",
              " 7: 'time',\n",
              " 8: 'character',\n",
              " 9: 'watch',\n",
              " 10: 'bad',\n",
              " 11: 'story',\n",
              " 12: 'think',\n",
              " 13: 'scene',\n",
              " 14: 'great',\n",
              " 15: 'know',\n",
              " 16: 'look',\n",
              " 17: 'people',\n",
              " 18: 'don',\n",
              " 19: 'love',\n",
              " 20: 'way',\n",
              " 21: 'play',\n",
              " 22: 'thing',\n",
              " 23: 'come',\n",
              " 24: 'find',\n",
              " 25: 'man',\n",
              " 26: 'end',\n",
              " 27: 'life',\n",
              " 28: 'actor',\n",
              " 29: 'plot',\n",
              " 30: 'work',\n",
              " 31: 'want',\n",
              " 32: 'year',\n",
              " 33: 'try',\n",
              " 34: 'little',\n",
              " 35: 'feel',\n",
              " 36: 'act',\n",
              " 37: 'm',\n",
              " 38: 've',\n",
              " 39: 'guy',\n",
              " 40: 'lot',\n",
              " 41: 'old',\n",
              " 42: 'director',\n",
              " 43: 'real',\n",
              " 44: 'didn',\n",
              " 45: 'funny',\n",
              " 46: 'performance',\n",
              " 47: 'doesn',\n",
              " 48: 'woman',\n",
              " 49: 'actually',\n",
              " 50: 'big',\n",
              " 51: '10',\n",
              " 52: 'role',\n",
              " 53: 'long',\n",
              " 54: 'leave',\n",
              " 55: 'tell',\n",
              " 56: 'start',\n",
              " 57: 'star',\n",
              " 58: 'cast',\n",
              " 59: 'young',\n",
              " 60: 'new',\n",
              " 61: 'horror',\n",
              " 62: 'day',\n",
              " 63: 'world',\n",
              " 64: 'point',\n",
              " 65: 'comedy',\n",
              " 66: 'girl',\n",
              " 67: 'minute',\n",
              " 68: 'pretty',\n",
              " 69: 'fact',\n",
              " 70: 'turn',\n",
              " 71: 'acting',\n",
              " 72: 'music',\n",
              " 73: 'happen',\n",
              " 74: 'action',\n",
              " 75: 'line',\n",
              " 76: 'set',\n",
              " 77: 'fan',\n",
              " 78: 'right',\n",
              " 79: 'friend',\n",
              " 80: 'kill',\n",
              " 81: 'write',\n",
              " 82: 'series',\n",
              " 83: 'need',\n",
              " 84: 'bit',\n",
              " 85: 'laugh',\n",
              " 86: 'enjoy',\n",
              " 87: 'isn',\n",
              " 88: 'script',\n",
              " 89: 'far',\n",
              " 90: 'live',\n",
              " 91: 'interesting',\n",
              " 92: 'mean',\n",
              " 93: 'd',\n",
              " 94: 'kid',\n",
              " 95: 'tv',\n",
              " 96: 'believe',\n",
              " 97: 'effect',\n",
              " 98: 'lead',\n",
              " 99: '2',\n",
              " 100: 'original',\n",
              " 101: 'kind',\n",
              " 102: 'll',\n",
              " 103: 'family',\n",
              " 104: 'let',\n",
              " 105: 'place',\n",
              " 106: 'reason',\n",
              " 107: 'fun',\n",
              " 108: 'probably',\n",
              " 109: 'book',\n",
              " 110: 'child',\n",
              " 111: 'away',\n",
              " 112: 'run',\n",
              " 113: 'hard',\n",
              " 114: 'screen',\n",
              " 115: 'war',\n",
              " 116: 'sure',\n",
              " 117: 'moment',\n",
              " 118: 'idea',\n",
              " 119: 'dvd',\n",
              " 120: 'audience',\n",
              " 121: 'help',\n",
              " 122: 'high',\n",
              " 123: 'especially',\n",
              " 124: 'episode',\n",
              " 125: 'expect',\n",
              " 126: 'sound',\n",
              " 127: 'read',\n",
              " 128: 'maybe',\n",
              " 129: 'win',\n",
              " 130: 'course',\n",
              " 131: 'fall',\n",
              " 132: 'sense',\n",
              " 133: 'boy',\n",
              " 134: 'worth',\n",
              " 135: 'short',\n",
              " 136: 'job',\n",
              " 137: 'american',\n",
              " 138: 'main',\n",
              " 139: 'different',\n",
              " 140: 'bring',\n",
              " 141: 'face',\n",
              " 142: 'use',\n",
              " 143: 'recommend',\n",
              " 144: 'problem',\n",
              " 145: 'black',\n",
              " 146: 'shoot',\n",
              " 147: 'half',\n",
              " 148: 'death',\n",
              " 149: 'special',\n",
              " 150: 'mind',\n",
              " 151: 'early',\n",
              " 152: 'second',\n",
              " 153: 'waste',\n",
              " 154: 'wasn',\n",
              " 155: 'true',\n",
              " 156: 'night',\n",
              " 157: 'money',\n",
              " 158: 'version',\n",
              " 159: 'hope',\n",
              " 160: 'budget',\n",
              " 161: 'hour',\n",
              " 162: 'instead',\n",
              " 163: 'talk',\n",
              " 164: 'head',\n",
              " 165: '1',\n",
              " 166: 'excellent',\n",
              " 167: 'hear',\n",
              " 168: 'later',\n",
              " 169: 'die',\n",
              " 170: 'miss',\n",
              " 171: 'low',\n",
              " 172: 'john',\n",
              " 173: 'beautiful',\n",
              " 174: 'classic',\n",
              " 175: 'follow',\n",
              " 176: 'wife',\n",
              " 177: 'lose',\n",
              " 178: 'change',\n",
              " 179: 'poor',\n",
              " 180: 'understand',\n",
              " 181: 'eye',\n",
              " 182: 'completely',\n",
              " 183: 'remember',\n",
              " 184: 'house',\n",
              " 185: 'production',\n",
              " 186: 'school',\n",
              " 187: 'piece',\n",
              " 188: 'begin',\n",
              " 189: '3',\n",
              " 190: 'release',\n",
              " 191: 'stupid',\n",
              " 192: 'camera',\n",
              " 193: 'human',\n",
              " 194: 'word',\n",
              " 195: 'nice',\n",
              " 196: 'direct',\n",
              " 197: 'include',\n",
              " 198: 'attempt',\n",
              " 199: 'view',\n",
              " 200: 'add',\n",
              " 201: 'appear',\n",
              " 202: 'feature',\n",
              " 203: 'game',\n",
              " 204: 'hand',\n",
              " 205: 'home',\n",
              " 206: 'video',\n",
              " 207: 'simply',\n",
              " 208: 'viewer',\n",
              " 209: 'couple',\n",
              " 210: 'dead',\n",
              " 211: 'suppose',\n",
              " 212: 'wrong',\n",
              " 213: 'care',\n",
              " 214: 'lack',\n",
              " 215: 'shot',\n",
              " 216: 'picture',\n",
              " 217: 'song',\n",
              " 218: 'title',\n",
              " 219: 'father',\n",
              " 220: 'involve',\n",
              " 221: 'truly',\n",
              " 222: 'rest',\n",
              " 223: 'fight',\n",
              " 224: 'ending',\n",
              " 225: 'hollywood',\n",
              " 226: 'sex',\n",
              " 227: 'flick',\n",
              " 228: 'terrible',\n",
              " 229: 'person',\n",
              " 230: 'writer',\n",
              " 231: 'save',\n",
              " 232: 'mother',\n",
              " 233: 'wonder',\n",
              " 234: 'style',\n",
              " 235: 'awful',\n",
              " 236: 'decide',\n",
              " 237: 'small',\n",
              " 238: 'sort',\n",
              " 239: 'review',\n",
              " 240: 'murder',\n",
              " 241: 'stop',\n",
              " 242: 'dialogue',\n",
              " 243: 'meet',\n",
              " 244: 'case',\n",
              " 245: 'joke',\n",
              " 246: 'guess',\n",
              " 247: 'close',\n",
              " 248: 'base',\n",
              " 249: 'definitely',\n",
              " 250: 'create',\n",
              " 251: 'perfect',\n",
              " 252: 'experience',\n",
              " 253: 'matter',\n",
              " 254: 'quality',\n",
              " 255: 'drama',\n",
              " 256: 'oh',\n",
              " 257: 'wonderful',\n",
              " 258: 'couldn',\n",
              " 259: 'sit',\n",
              " 260: 'certainly',\n",
              " 261: 'comment',\n",
              " 262: 'sequence',\n",
              " 263: 'absolutely',\n",
              " 264: 'spend',\n",
              " 265: 'example',\n",
              " 266: 'mention',\n",
              " 267: 'cinema',\n",
              " 268: 'boring',\n",
              " 269: 'dark',\n",
              " 270: 'overall',\n",
              " 271: 'finally',\n",
              " 272: 'yes',\n",
              " 273: 'late',\n",
              " 274: 'fine',\n",
              " 275: 'art',\n",
              " 276: 'deal',\n",
              " 277: 'cut',\n",
              " 278: 'force',\n",
              " 279: 'mr',\n",
              " 280: 'actress',\n",
              " 281: 'consider',\n",
              " 282: 'voice',\n",
              " 283: 'car',\n",
              " 284: '5',\n",
              " 285: 'final',\n",
              " 286: 'humor',\n",
              " 287: 'type',\n",
              " 288: '4',\n",
              " 289: 'hit',\n",
              " 290: 'totally',\n",
              " 291: 'entire',\n",
              " 292: 'buy',\n",
              " 293: 'direction',\n",
              " 294: 'hero',\n",
              " 295: 'able',\n",
              " 296: 'white',\n",
              " 297: 'rent',\n",
              " 298: 'wait',\n",
              " 299: 'stand',\n",
              " 300: 'hold',\n",
              " 301: 'favorite',\n",
              " 302: 'brother',\n",
              " 303: 'despite',\n",
              " 304: 'fail',\n",
              " 305: 'killer',\n",
              " 306: 'relationship',\n",
              " 307: 'age',\n",
              " 308: 'ask',\n",
              " 309: 'horrible',\n",
              " 310: 'throw',\n",
              " 311: 'stuff',\n",
              " 312: 'forget',\n",
              " 313: 'speak',\n",
              " 314: 'b',\n",
              " 315: 'son',\n",
              " 316: 'heart',\n",
              " 317: 'group',\n",
              " 318: 'today',\n",
              " 319: 'god',\n",
              " 320: 'light',\n",
              " 321: 'learn',\n",
              " 322: 'break',\n",
              " 323: 'pay',\n",
              " 324: 'rate',\n",
              " 325: 'evil',\n",
              " 326: 'wish',\n",
              " 327: 'hate',\n",
              " 328: 'open',\n",
              " 329: 'town',\n",
              " 330: 'daughter',\n",
              " 331: 'monster',\n",
              " 332: 'credit',\n",
              " 333: 'michael',\n",
              " 334: 'portray',\n",
              " 335: 'talent',\n",
              " 336: 'genre',\n",
              " 337: 'number',\n",
              " 338: 'walk',\n",
              " 339: 'unfortunately',\n",
              " 340: 'score',\n",
              " 341: 'manage',\n",
              " 342: 'etc',\n",
              " 343: 'brilliant',\n",
              " 344: 'power',\n",
              " 345: 'history',\n",
              " 346: 'stay',\n",
              " 347: 'present',\n",
              " 348: 'entertaining',\n",
              " 349: 'amazing',\n",
              " 350: 'city',\n",
              " 351: 'situation',\n",
              " 352: 'order',\n",
              " 353: 'question',\n",
              " 354: 'soon',\n",
              " 355: 'level',\n",
              " 356: 'theme',\n",
              " 357: 'obviously',\n",
              " 358: 'strong',\n",
              " 359: 'self',\n",
              " 360: 'past',\n",
              " 361: 'cool',\n",
              " 362: 'drive',\n",
              " 363: 'complete',\n",
              " 364: 'deserve',\n",
              " 365: 'robert',\n",
              " 366: 'slow',\n",
              " 367: 'chance',\n",
              " 368: 'body',\n",
              " 369: 'catch',\n",
              " 370: 'feeling',\n",
              " 371: 'highly',\n",
              " 372: 'return',\n",
              " 373: 'support',\n",
              " 374: 'pick',\n",
              " 375: 'event',\n",
              " 376: 'hilarious',\n",
              " 377: 'documentary',\n",
              " 378: 'country',\n",
              " 379: 'realize',\n",
              " 380: 'ok',\n",
              " 381: 'decent',\n",
              " 382: 'career',\n",
              " 383: 'simple',\n",
              " 384: 'team',\n",
              " 385: 'crap',\n",
              " 386: 'dog',\n",
              " 387: 'twist',\n",
              " 388: 'surprise',\n",
              " 389: 'reality',\n",
              " 390: 'beginning',\n",
              " 391: 'hell',\n",
              " 392: 'figure',\n",
              " 393: 'cop',\n",
              " 394: 'husband',\n",
              " 395: 'provide',\n",
              " 396: 'police',\n",
              " 397: 'dialog',\n",
              " 398: 'extremely',\n",
              " 399: 'drug',\n",
              " 400: 'blood',\n",
              " 401: 'cause',\n",
              " 402: 'grow',\n",
              " 403: 'effort',\n",
              " 404: 'interest',\n",
              " 405: 'deliver',\n",
              " 406: 'subject',\n",
              " 407: 'element',\n",
              " 408: 'thriller',\n",
              " 409: 'violence',\n",
              " 410: 'sister',\n",
              " 411: 'gore',\n",
              " 412: 'female',\n",
              " 413: 'sequel',\n",
              " 414: 'value',\n",
              " 415: 'result',\n",
              " 416: 'novel',\n",
              " 417: 'wouldn',\n",
              " 418: 'opinion',\n",
              " 419: 'check',\n",
              " 420: 'david',\n",
              " 421: 'seriously',\n",
              " 422: 'room',\n",
              " 423: 'english',\n",
              " 424: '80',\n",
              " 425: 'huge',\n",
              " 426: 'ago',\n",
              " 427: 'silly',\n",
              " 428: 'allow',\n",
              " 429: 'exactly',\n",
              " 430: 'particularly',\n",
              " 431: 'rating',\n",
              " 432: 'possible',\n",
              " 433: 'james',\n",
              " 434: 'theater',\n",
              " 435: 'producer',\n",
              " 436: 'scary',\n",
              " 437: 'note',\n",
              " 438: 'produce',\n",
              " 439: 'obvious',\n",
              " 440: 'strange',\n",
              " 441: 'compare',\n",
              " 442: 'cover',\n",
              " 443: 'sad',\n",
              " 444: 'happy',\n",
              " 445: 'spoiler',\n",
              " 446: 'important',\n",
              " 447: 'clear',\n",
              " 448: 'french',\n",
              " 449: 'jack',\n",
              " 450: 'western',\n",
              " 451: 'offer',\n",
              " 452: 'soundtrack',\n",
              " 453: 'parent',\n",
              " 454: 'explain',\n",
              " 455: 'ridiculous',\n",
              " 456: 'steal',\n",
              " 457: 'touch',\n",
              " 458: 'member',\n",
              " 459: 'cinematography',\n",
              " 460: 'cheap',\n",
              " 461: 'fill',\n",
              " 462: 'usually',\n",
              " 463: 'middle',\n",
              " 464: 'dance',\n",
              " 465: 'local',\n",
              " 466: 'deep',\n",
              " 467: 'attention',\n",
              " 468: 'image',\n",
              " 469: 'form',\n",
              " 470: 'space',\n",
              " 471: 'tale',\n",
              " 472: 'pull',\n",
              " 473: 'focus',\n",
              " 474: 'television',\n",
              " 475: 'remain',\n",
              " 476: 'easy',\n",
              " 477: 'suspense',\n",
              " 478: 'alien',\n",
              " 479: 'non',\n",
              " 480: 'fast',\n",
              " 481: 'basically',\n",
              " 482: 'crime',\n",
              " 483: 'class',\n",
              " 484: 'message',\n",
              " 485: 'doctor',\n",
              " 486: 'lady',\n",
              " 487: 'stick',\n",
              " 488: 'dream',\n",
              " 489: 'rock',\n",
              " 490: 'avoid',\n",
              " 491: 'comic',\n",
              " 492: 'escape',\n",
              " 493: 'dr',\n",
              " 494: 'major',\n",
              " 495: 'state',\n",
              " 496: 'pace',\n",
              " 497: 'somewhat',\n",
              " 498: 'imagine',\n",
              " 499: 'usual',\n",
              " 500: 'earth',\n",
              " 501: 'water',\n",
              " 502: 'modern',\n",
              " 503: 'musical',\n",
              " 504: 'doubt',\n",
              " 505: 'air',\n",
              " 506: 'train',\n",
              " 507: 'copy',\n",
              " 508: 'near',\n",
              " 509: '7',\n",
              " 510: 'apparently',\n",
              " 511: 'thank',\n",
              " 512: 'single',\n",
              " 513: 'gun',\n",
              " 514: 'straight',\n",
              " 515: 'bunch',\n",
              " 516: 'certain',\n",
              " 517: 'enjoyable',\n",
              " 518: 'street',\n",
              " 519: 'wear',\n",
              " 520: 'annoying',\n",
              " 521: 'capture',\n",
              " 522: '8',\n",
              " 523: 'haven',\n",
              " 524: 'opening',\n",
              " 525: 'agree',\n",
              " 526: 'send',\n",
              " 527: 'plan',\n",
              " 528: 'prove',\n",
              " 529: 'sorry',\n",
              " 530: 'having',\n",
              " 531: 'vampire',\n",
              " 532: 'o',\n",
              " 533: 'remind',\n",
              " 534: 'crew',\n",
              " 535: 'clearly',\n",
              " 536: 'aren',\n",
              " 537: 'gay',\n",
              " 538: 'chase',\n",
              " 539: 'soldier',\n",
              " 540: 'pass',\n",
              " 541: 'entertainment',\n",
              " 542: 'george',\n",
              " 543: 'fire',\n",
              " 544: 'detail',\n",
              " 545: 'season',\n",
              " 546: 'okay',\n",
              " 547: 'emotion',\n",
              " 548: 'cartoon',\n",
              " 549: 'discover',\n",
              " 550: 'carry',\n",
              " 551: 'student',\n",
              " 552: 'date',\n",
              " 553: 'british',\n",
              " 554: 'dull',\n",
              " 555: 'predictable',\n",
              " 556: 'issue',\n",
              " 557: 'draw',\n",
              " 558: 'suck',\n",
              " 559: 'aspect',\n",
              " 560: 'villain',\n",
              " 561: 'weak',\n",
              " 562: 'similar',\n",
              " 563: 'blow',\n",
              " 564: 'filmmaker',\n",
              " 565: 'future',\n",
              " 566: 'build',\n",
              " 567: '20',\n",
              " 568: 'fit',\n",
              " 569: 'visual',\n",
              " 570: '9',\n",
              " 571: 'box',\n",
              " 572: 'storyline',\n",
              " 573: 'hot',\n",
              " 574: 'battle',\n",
              " 575: 'victim',\n",
              " 576: 'notice',\n",
              " 577: 'choose',\n",
              " 578: 'material',\n",
              " 579: 'typical',\n",
              " 580: 'island',\n",
              " 581: 'party',\n",
              " 582: 'believable',\n",
              " 583: 'king',\n",
              " 584: 'mystery',\n",
              " 585: 'develop',\n",
              " 586: 'match',\n",
              " 587: 'romantic',\n",
              " 588: 'reveal',\n",
              " 589: 'famous',\n",
              " 590: 'fi',\n",
              " 591: 'lie',\n",
              " 592: 'period',\n",
              " 593: 'easily',\n",
              " 594: 'large',\n",
              " 595: 'bear',\n",
              " 596: 'eat',\n",
              " 597: 'male',\n",
              " 598: 'average',\n",
              " 599: 'stage',\n",
              " 600: 'contain',\n",
              " 601: 'peter',\n",
              " 602: 'sci',\n",
              " 603: 'masterpiece',\n",
              " 604: 'writing',\n",
              " 605: 'oscar',\n",
              " 606: 'brain',\n",
              " 607: 'standard',\n",
              " 608: 'beat',\n",
              " 609: 'attack',\n",
              " 610: 'teen',\n",
              " 611: 'lame',\n",
              " 612: 'shame',\n",
              " 613: 'fantastic',\n",
              " 614: 'week',\n",
              " 615: 'mark',\n",
              " 616: 'ride',\n",
              " 617: 'appreciate',\n",
              " 618: 'realistic',\n",
              " 619: 'cry',\n",
              " 620: 'list',\n",
              " 621: 'dumb',\n",
              " 622: 'nearly',\n",
              " 623: 'describe',\n",
              " 624: 'disappoint',\n",
              " 625: 'free',\n",
              " 626: 'bother',\n",
              " 627: 'footage',\n",
              " 628: 'richard',\n",
              " 629: 'society',\n",
              " 630: 'continue',\n",
              " 631: 'studio',\n",
              " 632: 'bill',\n",
              " 633: 'gets',\n",
              " 634: 'master',\n",
              " 635: 'location',\n",
              " 636: 'fly',\n",
              " 637: 'america',\n",
              " 638: '70',\n",
              " 639: 'premise',\n",
              " 640: 'choice',\n",
              " 641: 'truth',\n",
              " 642: 'cheesy',\n",
              " 643: 'tom',\n",
              " 644: 'general',\n",
              " 645: 'emotional',\n",
              " 646: 'mess',\n",
              " 647: 'atmosphere',\n",
              " 648: 'bore',\n",
              " 649: 'treat',\n",
              " 650: 'beauty',\n",
              " 651: 'inside',\n",
              " 652: 'imdb',\n",
              " 653: 'secret',\n",
              " 654: 'red',\n",
              " 655: 'adult',\n",
              " 656: 'memorable',\n",
              " 657: 'forward',\n",
              " 658: 'romance',\n",
              " 659: 'poorly',\n",
              " 660: 'weird',\n",
              " 661: 'finish',\n",
              " 662: 'difficult',\n",
              " 663: 'background',\n",
              " 664: 'accent',\n",
              " 665: 'century',\n",
              " 666: 'badly',\n",
              " 667: 'perfectly',\n",
              " 668: 'e',\n",
              " 669: 'sexual',\n",
              " 670: 'actual',\n",
              " 671: 'admit',\n",
              " 672: 'particular',\n",
              " 673: 'rich',\n",
              " 674: 'adventure',\n",
              " 675: 'lover',\n",
              " 676: 'personal',\n",
              " 677: 'blue',\n",
              " 678: 'plus',\n",
              " 679: 'girlfriend',\n",
              " 680: 'eventually',\n",
              " 681: 'entertain',\n",
              " 682: 'project',\n",
              " 683: 'animation',\n",
              " 684: 'baby',\n",
              " 685: 'control',\n",
              " 686: 'surprised',\n",
              " 687: 'suggest',\n",
              " 688: 'wood',\n",
              " 689: 'fear',\n",
              " 690: 'previous',\n",
              " 691: 'quickly',\n",
              " 692: 'zombie',\n",
              " 693: 'odd',\n",
              " 694: 'total',\n",
              " 695: 'editing',\n",
              " 696: 'rip',\n",
              " 697: 'crazy',\n",
              " 698: 'company',\n",
              " 699: 'creature',\n",
              " 700: 'channel',\n",
              " 701: 'remake',\n",
              " 702: '30',\n",
              " 703: 'german',\n",
              " 704: 'term',\n",
              " 705: 'interested',\n",
              " 706: 'track',\n",
              " 707: 'memory',\n",
              " 708: 'business',\n",
              " 709: 'nature',\n",
              " 710: 'post',\n",
              " 711: 'screenplay',\n",
              " 712: 'unique',\n",
              " 713: 'perform',\n",
              " 714: 'shock',\n",
              " 715: 'maker',\n",
              " 716: 'possibly',\n",
              " 717: 'powerful',\n",
              " 718: 'struggle',\n",
              " 719: 'accept',\n",
              " 720: 'success',\n",
              " 721: 'superb',\n",
              " 722: 'cat',\n",
              " 723: 'scream',\n",
              " 724: 'thought',\n",
              " 725: 'political',\n",
              " 726: 'incredibly',\n",
              " 727: 'hole',\n",
              " 728: '90',\n",
              " 729: 'fairly',\n",
              " 730: 'plenty',\n",
              " 731: 'development',\n",
              " 732: 'serve',\n",
              " 733: 'fantasy',\n",
              " 734: 'de',\n",
              " 735: 'f',\n",
              " 736: 'york',\n",
              " 737: 'store',\n",
              " 738: 'italian',\n",
              " 739: 'player',\n",
              " 740: 'plain',\n",
              " 741: 'apart',\n",
              " 742: 'land',\n",
              " 743: 'soul',\n",
              " 744: 'award',\n",
              " 745: 'language',\n",
              " 746: 'respect',\n",
              " 747: 'joe',\n",
              " 748: 'suffer',\n",
              " 749: 'animal',\n",
              " 750: 'japanese',\n",
              " 751: 'depth',\n",
              " 752: 'park',\n",
              " 753: 'paul',\n",
              " 754: 'creepy',\n",
              " 755: 'gang',\n",
              " 756: 'camp',\n",
              " 757: 'kick',\n",
              " 758: 'costume',\n",
              " 759: 'band',\n",
              " 760: 'van',\n",
              " 761: '50',\n",
              " 762: 'trouble',\n",
              " 763: 'ability',\n",
              " 764: 'portrayal',\n",
              " 765: 'dress',\n",
              " 766: 'answer',\n",
              " 767: 'travel',\n",
              " 768: 'appearance',\n",
              " 769: 'concept',\n",
              " 770: 'anti',\n",
              " 771: 'dramatic',\n",
              " 772: 'clever',\n",
              " 773: 'outside',\n",
              " 774: 'judge',\n",
              " 775: 'tear',\n",
              " 776: 'fake',\n",
              " 777: 'pop',\n",
              " 778: 'roll',\n",
              " 779: 'c',\n",
              " 780: 'drag',\n",
              " 781: 'mad',\n",
              " 782: 'yeah',\n",
              " 783: 'sell',\n",
              " 784: 'era',\n",
              " 785: 'step',\n",
              " 786: 'recently',\n",
              " 787: 'listen',\n",
              " 788: 'destroy',\n",
              " 789: 'william',\n",
              " 790: 'hair',\n",
              " 791: '6',\n",
              " 792: 'spot',\n",
              " 793: 'spirit',\n",
              " 794: 'hitchcock',\n",
              " 795: 'public',\n",
              " 796: 'law',\n",
              " 797: 'alive',\n",
              " 798: 'appeal',\n",
              " 799: 'cute',\n",
              " 800: 'search',\n",
              " 801: 'million',\n",
              " 802: 'mix',\n",
              " 803: 'culture',\n",
              " 804: 'bed',\n",
              " 805: 'office',\n",
              " 806: 'science',\n",
              " 807: 'smart',\n",
              " 808: 'disney',\n",
              " 809: 'color',\n",
              " 810: 'door',\n",
              " 811: '15',\n",
              " 812: 'college',\n",
              " 813: 'flat',\n",
              " 814: 'hide',\n",
              " 815: 'setting',\n",
              " 816: 'introduce',\n",
              " 817: 'rise',\n",
              " 818: 'jump',\n",
              " 819: 'entirely',\n",
              " 820: 'humour',\n",
              " 821: 'taste',\n",
              " 822: 'design',\n",
              " 823: 'mistake',\n",
              " 824: 'flaw',\n",
              " 825: 'sleep',\n",
              " 826: 'nudity',\n",
              " 827: 'marry',\n",
              " 828: 'u',\n",
              " 829: 'slightly',\n",
              " 830: 'race',\n",
              " 831: 'fiction',\n",
              " 832: 'purpose',\n",
              " 833: 'la',\n",
              " 834: 'pure',\n",
              " 835: 'ed',\n",
              " 836: 'road',\n",
              " 837: 'tension',\n",
              " 838: 'exist',\n",
              " 839: 'unlike',\n",
              " 840: 'ship',\n",
              " 841: 'co',\n",
              " 842: 'trash',\n",
              " 843: 'popular',\n",
              " 844: 'scientist',\n",
              " 845: 'got',\n",
              " 846: 'pathetic',\n",
              " 847: 'torture',\n",
              " 848: 'sick',\n",
              " 849: 'hurt',\n",
              " 850: 'relate',\n",
              " 851: 'reach',\n",
              " 852: 'edge',\n",
              " 853: 'teenager',\n",
              " 854: 'common',\n",
              " 855: 'hardly',\n",
              " 856: 'extra',\n",
              " 857: 'count',\n",
              " 858: 'plane',\n",
              " 859: 'claim',\n",
              " 860: 'intelligent',\n",
              " 861: 'lee',\n",
              " 862: 'bond',\n",
              " 863: 'incredible',\n",
              " 864: 'cross',\n",
              " 865: 'silent',\n",
              " 866: 'available',\n",
              " 867: 'giant',\n",
              " 868: 'ring',\n",
              " 869: 'aside',\n",
              " 870: 'talented',\n",
              " 871: 'record',\n",
              " 872: 'share',\n",
              " 873: 'sing',\n",
              " 874: 'pointless',\n",
              " 875: 'agent',\n",
              " 876: 'promise',\n",
              " 877: 'amusing',\n",
              " 878: 'genius',\n",
              " 879: 'ruin',\n",
              " 880: 'horse',\n",
              " 881: 'reference',\n",
              " 882: 'cold',\n",
              " 883: 'suddenly',\n",
              " 884: 'survive',\n",
              " 885: 'suspect',\n",
              " 886: 'jones',\n",
              " 887: 'interview',\n",
              " 888: 'familiar',\n",
              " 889: 'normal',\n",
              " 890: 'honest',\n",
              " 891: 'folk',\n",
              " 892: 'intend',\n",
              " 893: 'critic',\n",
              " 894: 'sexy',\n",
              " 895: 'trip',\n",
              " 896: 'approach',\n",
              " 897: 'positive',\n",
              " 898: 'fair',\n",
              " 899: 'potential',\n",
              " 900: 'mood',\n",
              " 901: 'sam',\n",
              " 902: 'inspire',\n",
              " 903: 'violent',\n",
              " 904: 'sadly',\n",
              " 905: 'successful',\n",
              " 906: 'bizarre',\n",
              " 907: 'club',\n",
              " 908: 'journey',\n",
              " 909: 'receive',\n",
              " 910: 'cost',\n",
              " 911: 'conclusion',\n",
              " 912: 'grade',\n",
              " 913: 'army',\n",
              " 914: 'area',\n",
              " 915: 'tough',\n",
              " 916: 'tone',\n",
              " 917: 'garbage',\n",
              " 918: 'affair',\n",
              " 919: 'burn',\n",
              " 920: 'wind',\n",
              " 921: 'raise',\n",
              " 922: 'ray',\n",
              " 923: 'machine',\n",
              " 924: 'awesome',\n",
              " 925: 'hang',\n",
              " 926: 'buddy',\n",
              " 927: 'seek',\n",
              " 928: 'gag',\n",
              " 929: 'personality',\n",
              " 930: 'arrive',\n",
              " 931: 'adaptation',\n",
              " 932: 'west',\n",
              " 933: 'sweet',\n",
              " 934: 'repeat',\n",
              " 935: 'likely',\n",
              " 936: 'rape',\n",
              " 937: 'south',\n",
              " 938: 'basic',\n",
              " 939: 'government',\n",
              " 940: 'prison',\n",
              " 941: 'barely',\n",
              " 942: 'suit',\n",
              " 943: 'bar',\n",
              " 944: 'drop',\n",
              " 945: 'literally',\n",
              " 946: 'ghost',\n",
              " 947: 'exciting',\n",
              " 948: 'ryan',\n",
              " 949: 'everybody',\n",
              " 950: 'crash',\n",
              " 951: 'impressive',\n",
              " 952: 'radio',\n",
              " 953: '100',\n",
              " 954: 'slasher',\n",
              " 955: 'wall',\n",
              " 956: 'weren',\n",
              " 957: 'g',\n",
              " 958: 'scare',\n",
              " 959: 'rule',\n",
              " 960: 'immediately',\n",
              " 961: 'naked',\n",
              " 962: 'display',\n",
              " 963: 'super',\n",
              " 964: 'study',\n",
              " 965: 'personally',\n",
              " 966: 'gem',\n",
              " 967: 'social',\n",
              " 968: 'impossible',\n",
              " 969: 'recent',\n",
              " 970: 'warn',\n",
              " 971: 'surprisingly',\n",
              " 972: 'opera',\n",
              " 973: 'making',\n",
              " 974: 'concern',\n",
              " 975: 'climax',\n",
              " 976: 'ground',\n",
              " 977: 'ultimately',\n",
              " 978: 'strike',\n",
              " 979: 'charm',\n",
              " 980: 'scenery',\n",
              " 981: 'foot',\n",
              " 982: 'honestly',\n",
              " 983: 'succeed',\n",
              " 984: 'depict',\n",
              " 985: 'snake',\n",
              " 986: 'presence',\n",
              " 987: 'effective',\n",
              " 988: 'solid',\n",
              " 989: 'convincing',\n",
              " 990: 'computer',\n",
              " 991: 'indian',\n",
              " 992: 'ex',\n",
              " 993: 'excuse',\n",
              " 994: 'difference',\n",
              " 995: 'teacher',\n",
              " 996: 'expectation',\n",
              " 997: 'innocent',\n",
              " 998: 'hey',\n",
              " 999: 'enter',\n",
              " 1000: 'handle',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "tokenizer.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1BQO2aNRRTQ8"
      },
      "outputs": [],
      "source": [
        "train_pad = tf.keras.preprocessing.sequence.pad_sequences(train_ds.text_encoded, padding=\"post\")\n",
        "test_pad = tf.keras.preprocessing.sequence.pad_sequences(test_ds.text_encoded, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Dcf6vY-3Yh0f"
      },
      "outputs": [],
      "source": [
        "# We'll use this to form a tensorflow dataset containing on the one hand\n",
        "# the encoded texts and the labels.\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_pad, train_ds.Label))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_pad, test_ds.Label))\n",
        "\n",
        "# We then organize the dataste per batch\n",
        "train_ds = train_ds.shuffle(len(train_ds)).batch(1024)\n",
        "\n",
        "test_ds = test_ds.shuffle(len(test_ds)).batch(1024)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_QQR-yJvWbhH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEyurcdokhcn"
      },
      "source": [
        "# **Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=16 # the dimensionality of the representation space\n",
        "\n",
        "vocab_size = tokenizer.num_words # the number of words in the vocabulary\n",
        "model = Sequential([\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"), # the embedding layer\n",
        "  # the input dim needs to be equal to the size of the vocabulary + 1 (because of\n",
        "  # the zero padding)\n",
        "  GlobalAveragePooling1D(), # this will pick the average for every word in the sentence\n",
        "  # along each dimension of the representation space.\n",
        "  Dense(16, activation='relu'), # a dense layer\n",
        "  Dense(1, activation=\"sigmoid\") # the prediction layer\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOr1mEkmWvuH",
        "outputId": "da87bee7-7d42-45c7-d865-435d0973b111"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 16)          160000    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs2\")\n"
      ],
      "metadata": {
        "id": "ICxPlSOPW8ut"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "npmwMWMqXBjo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=15,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2SnblgkXZVo",
        "outputId": "7279ed69-d0a0-4863-a65d-24446a88978f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 3s 113ms/step - loss: 0.2699 - accuracy: 0.9127 - val_loss: 0.3201 - val_accuracy: 0.8783\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 2s 97ms/step - loss: 0.2638 - accuracy: 0.9151 - val_loss: 0.3158 - val_accuracy: 0.8796\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 2s 102ms/step - loss: 0.2582 - accuracy: 0.9165 - val_loss: 0.3158 - val_accuracy: 0.8789\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 3s 142ms/step - loss: 0.2540 - accuracy: 0.9160 - val_loss: 0.3096 - val_accuracy: 0.8808\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 2s 108ms/step - loss: 0.2480 - accuracy: 0.9204 - val_loss: 0.3094 - val_accuracy: 0.8808\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 2s 104ms/step - loss: 0.2443 - accuracy: 0.9202 - val_loss: 0.3032 - val_accuracy: 0.8831\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 2s 105ms/step - loss: 0.2391 - accuracy: 0.9223 - val_loss: 0.3007 - val_accuracy: 0.8835\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 2s 104ms/step - loss: 0.2349 - accuracy: 0.9237 - val_loss: 0.2984 - val_accuracy: 0.8848\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 2s 106ms/step - loss: 0.2308 - accuracy: 0.9249 - val_loss: 0.2969 - val_accuracy: 0.8845\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 2s 107ms/step - loss: 0.2266 - accuracy: 0.9262 - val_loss: 0.2941 - val_accuracy: 0.8845\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 2s 103ms/step - loss: 0.2230 - accuracy: 0.9270 - val_loss: 0.2921 - val_accuracy: 0.8852\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 2s 106ms/step - loss: 0.2189 - accuracy: 0.9278 - val_loss: 0.2905 - val_accuracy: 0.8861\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 2s 105ms/step - loss: 0.2162 - accuracy: 0.9283 - val_loss: 0.2883 - val_accuracy: 0.8859\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 2s 134ms/step - loss: 0.2119 - accuracy: 0.9299 - val_loss: 0.2870 - val_accuracy: 0.8856\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 2s 128ms/step - loss: 0.2085 - accuracy: 0.9308 - val_loss: 0.2867 - val_accuracy: 0.8875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7da926a3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#writer = tf.summary.create_file_writer(\"/content/logs2\")"
      ],
      "metadata": {
        "id": "lvh3GYJPMC1T"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs_infra: no_execute\n",
        "#%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kly0VFvrXbst",
        "outputId": "ed3a5688-302c-4c0b-cf1c-b5fc9863b853"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard --log_dir logs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "jZgutryJm0OX",
        "outputId": "dfcf116f-cccd-4195-e198-0bfe62ee330b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "Error: A logdir or db must be specified. For example `tensorboard --logdir mylogdir` or `tensorboard --db sqlite:~/.tensorboard.db`. Run `tensorboard --helpfull` for details and examples."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "vocab = [value for value in tokenizer.index_word.values()][:1000]\n",
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "\n",
        "log_dir = \"/content/logs2\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "out_v = io.open(log_dir+\"/vectors.tsv\", 'w', encoding='utf-8')\n",
        "out_m = io.open(log_dir+\"/metadata.tsv\", 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "08hs1GP-Lh5m"
      },
      "execution_count": 61,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa+IDEgaPsdBQgGxHtP+/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}